# -----------------------------------------------------------------------------
# Calculates the Added Masses for a given shape dataset using Salome Meca
# -----------------------------------------------------------------------------
# Performs the following steps consecutively:
# - Reads a dataset of points (generated by generate_dataset.py)
# - Generates geometry and mesh using Salome Meca GEOM and SMESH
# - Generates Code_Aster configuration and calculation files (export, .comm)
# - Optionnaly runs Code_Aster calculations
# -----------------------------------------------------------------------------
# Credits/Copyright:
# - Hassan BERRO <hassan.berro@edf.fr>
# - Charbel HABCHI <habchi.charbel@gmail.com>
# -----------------------------------------------------------------------------
#
# Usage:
# ------
#
# **Within a Salome Meca (2022) shell**, run :
#
# python calculate.py
#
# -----------------------------------------------------------------------------

import os
import shutil
import stat
import time
import traceback

import numpy as np
from resources import utilities as ut

osp = os.path

#-------------------------------#
# U S E R   P A R A M E T E R S #
#-------------------------------#

ut.DEBUG = False     # Activate/Deactivate Debug messages
DATASET_ID = None    # If None, the latest generated dataset is handled
BOX_DIMS = [4., 4.]  # Meshing box dimensions (DX, DY)
RUN_ASTER = True     # Automatically run Code_Aster when mesh is generated

# G E O M   &   M E S H   B U I L D E R   C L A S S
# -----------------------------------------------------------------------------

class SalomeMecaRunner:
    """
    Class that generates the geometry and mesh in Salome Meca and then uses
    code_aster API to run Added mass calculations (optional).
    """

    # Public attributes
    output_dir = None                   # Output directory (<coords_dir>/../calcs)
    ca_export = ca_template = None      # Code_Aster templates for export and comm files
    shapes = None                       # Dictionnary {<shape_id> : </path/csv_fn>}

    # Private attributes
    _blocked = _run = None              # Boolean flags

    # Salome Meca resources (SALOME and AsterStudy)
    as_calc_api = as_file_attr = None   # AsterStudy API classes
    salome_study = study_builder = None # Salome study classes
    gbuild  = orig = rect = z_ax = None # Salome GEOM classes and utility objs
    smeshb = None                       # Salome SMESH builder class

    def __init__(self, coords_dir, run=True):
        """
        Initialize runner by loading the necessary SALOME modules and
        loading the coordinates csv files (from coords_dir).

        CSV file paths are saved in the dictionnary (shapes).

        Once initialized, an individual build of geometry and mesh can be
        done by calling the .build function with the shape id (sid). If
        the run flag is set to True (default), then Code_Aster calculations
        are executed automatically.

        Example:

        runner = SalomeMecaRunner('/path/to/points/dir', '/path/to/template')
        runner.run('shape_0001')

        - alternatively - to run all cases (note that this can be lengthy)
        runner.run_all()
        """
        ut.print_('init', f'Initialization in progress', 'bold')

        # Save the (run) choice given by the user = do run Code_Aster
        self._run = run

        # Check that the input directory exists and contains CSV files,
        # Read those file paths to self.shapes
        ut.print_(' ', f'Checking input shapes (coords) directory...')
        if not osp.isdir(coords_dir):
            ut.print_nook(f'Directory not found!')
            ut.print_('debug', coords_dir)
            self._blocked = True; return
        else:
            paths = ut.list_files(coords_dir, 'csv')
            if len(paths):
                ut.print_ok(f'Directory found and contains {len(paths)} '\
                             'CSV files')
                # Save a dictionnary : {'shape_1' : (Path to shape_1.csv)}
                # That is used later on for loading the input coordinates...
                self.shapes = {p.name.replace('.csv', ''): p \
                               for p in paths}
            else:
                ut.print_nook(f'Directory found, but it is empty!')
                ut.print_('debug', coords_dir)
                self._blocked = True; return

        ut.print_(' ', f'Checking code_aster .comm template')
        resources_dir =  osp.join(osp.dirname(__file__), 'resources')
        template_comm_fn = osp.join(resources_dir, 'template.comm')
        if not osp.isfile(template_comm_fn) :
            ut.print_nook(f'Template file not found!')
            ut.print_('debug', coords_dir)
            self._blocked = True; return
        else:
            with open(template_comm_fn, 'r') as tf:
                self.ca_template = tf.read()
            ut.print_ok(f'Found and ready')

        # Export file template (warning if fails since AsterStudy API does
        # not really need this
        ut.print_(' ', f'Checking code_aster export template')
        template_expt_fn = osp.join(resources_dir, 'template.export')
        if osp.isfile(template_expt_fn):
            with open(template_expt_fn, 'r') as tf:
                self.ca_export = tf.read()
            ut.print_ok('Export file will be generated in the calculation dirs')
        else:
            ut.print_('warn', 'Export file will not be generated')

        ut.print_(' ', f'Loading Salome components...')
        # Initialize salome components silently in the background
        if self.init_salome() is False:
            self._blocked = True; return

        ut.print_(' ', f'Preparing output directory...')
        self.output_dir = osp.join(osp.dirname(coords_dir), 'calcs')
        self.output_dir = osp.realpath(self.output_dir)
        ut.print_('debug', self.output_dir)

        if not osp.isdir(self.output_dir):
            os.makedirs(self.output_dir)
            ut.print_ok(f'Successfully created')
        else:
            ut.print_ok(f'Already exists')


    def init_salome(self):
        """
        Try to initialize Salome and emit errors properly if it fails
        """
        tref = time.time()
        errors = []
        with ut.suppress_stdout_stderr():
            try:
                self._do_init_salome()
            except Exception as e:
                errors = ['Salome environment is missing, cannot continue !',
                          '-'*75, str(e)]
                errors.extend(traceback.format_exc().strip().split('\n'))
                errors.append('-'*75)

        if errors:
            ut.print_nook(errors[0])
            ut.print_('debug', errors[1:])
            return False
        else:
            delta_sec = time.time() - tref
            ut.print_ok(f'Sucessfully loaded ({round(delta_sec, 2)}s)')

        return True

    @ut.timing
    def _do_init_salome(self):
        """
        Initialize all necessary salome components
        """
        import GEOM
        import salome
        import SMESH

        from salome.geom import geomBuilder, geomtools
        from salome.smesh import smeshBuilder
        from asterstudy.api import Calculation, FileAttr

        self.gbuild = geomBuilder.New()
        self.smeshb = smeshBuilder.New()
        self.smeshb.SMESH = SMESH
        self.smeshb.BUILDER = smeshBuilder
        self.as_calc_api, self.as_file_attr = Calculation, FileAttr


        self.salome_study = salome.myStudy
        self.study_builder = self.salome_study.NewBuilder()

        # Basic reference items
        self.orig = self.gbuild.MakeVertex(0, 0, 0)
        self.z_ax = self.gbuild.MakeVectorDXDYDZ(0, 0, 1)
        self.rect = self.gbuild.MakeFaceHW(BOX_DIMS[0], BOX_DIMS[1], 1)

    def create_group_on_subshape(self, compound, gobj, gname, stype,
                                 sub_shapes):
        """
        Create group on a subshape of the compound where gobj lies

        not_on flag allows to create group on all other subshapes
        """
        gb = self.gbuild
        group = gb.CreateGroup(compound, gb.ShapeType[stype])
        close_subshapes = [ss for ss in sub_shapes \
                           if gb.MinDistance(ss, gobj) < 1.e-8]

        if stype == 'VERTEX':
            elem_id = gb.GetSubShapeID(compound, close_subshapes[0])
            gb.AddObject(group, elem_id)
            objs = [close_subshapes[0]]
        else:
            objs = []
            for sub_shape in close_subshapes:
                cut = gb.MakeCut(sub_shape, gobj)
                vertices = gb.ExtractShapes(cut, gb.ShapeType['VERTEX'])
                if len(vertices) == 0:
                    elem_id = gb.GetSubShapeID(compound, sub_shape)
                    gb.AddObject(group, elem_id)
                    objs.append(sub_shape)

        gb.addToStudyInFather(compound, group, gname)
        return group, objs

    def run_all(self):
        """
        Builds all geometries
        """
        sids = list(self.shapes.keys())
        sids.sort()
        for sid in sids:
            self.run(sid)

        # --------------------------------------------------------------
        # Extra : create a global script for running all calculations
        # using the run_aster script. Note that this is not needed if
        # calculations are run using this class (run=True) and is thus
        # only generated in debug mode...
        # --------------------------------------------------------------
        if ut.DEBUG:
            runner_fn = osp.join(self.output_dir, 'runner.sh')
            with open(runner_fn, 'w') as rf:
                rf.write(r"""
#!/bin/bash
# ----------------------------------------------------------------------
# Runs all calculations using run_aster
# Note that this is not needed if the SalomeMecaRunner is initialized
# with run=True flag, as calculations are executed within Salome using
# the code_aster API.
# ----------------------------------------------------------------------
set_prefix() {
    local this=$(readlink -n -f "$1")
    prefix=$(dirname "${this}")
}
set_prefix "${0}"

echo "-------------------------------------------------"
echo "Launching $(find $prefix -name export | wc -l) tests"
echo "Dataset : $prefix"
echo "-------------------------------------------------"

# Actual launching of the calculations...
find $prefix -name export -exec run_aster {} \;

# When the results are finished, use the following convenient grep
# command to access valuable info in the message.txt file
# > grep Added */message.txt -A 3 -B 2
""".lstrip())

            st = os.stat(runner_fn)
            os.chmod(runner_fn, st.st_mode | stat.S_IEXEC)


    def run(self, sid):
        """
        Builds a geometry and mesh for the given shape id (sid), optionaly
        runs Code_Aster calculations when finished.
        """
        ut.print_('prep', f'[{sid}] is being prepared for calculation', 'bold')
        if self._blocked:
            ut.print_('error', 'Build is currently blocked, check previous errors')
            return

        # -=-=-=-=-=- I N I T I A L I Z A T I O N S -=-=-=-=-=-
        #
        # Create the calculation directories and read the shape information
        #

        # Verify that the provided shape ID exists (i.e. a corresponding
        # CSV file does exist in the points directory)
        path = self.shapes.get(sid, None)
        if path is None:
            ut.print_('error', f'Invalid shape ID : "{sid}"')

        # Create the individual calculation directory
        out_dir = osp.join(self.output_dir, sid)
        if not osp.isdir(out_dir):
            os.makedirs(out_dir)
            ut.print_('debug', f'Created {out_dir}')

        # Read point coordinates defining the shape to be calculated using
        # the csv file
        coords = np.genfromtxt(path, delimiter=' ', dtype=float)[:, :2]
        ut.print_('debug', f'Read {len(coords)} points from {path.name}')

        # Create a symbolic link to the image for each shape (easier verifification)
        img_ref_fn = osp.abspath(osp.join(self.output_dir, '..', 'images', f'{sid}.png'))
        img_dest_fn = osp.join(out_dir, 'image.png')
        if not osp.isfile(img_dest_fn):
            os.symlink(img_ref_fn, img_dest_fn)
        ut.print_('debug', f'Created symbolic link to {img_ref_fn}')

        # -=-=-=-=-=- G E O M E T R Y -=-=-=-=-=-
        #
        # Generate geometry using the GEOM module of SalomeMeca
        #

        # Convention : objects named as starting with _ are used for construction
        # and do not present an interest in themselve in the final mesh...

        gb = self.gbuild        # Shortcut to GEOM builder
        st = gb.ShapeType
        ss_sorted = gb.SubShapeAllSortedCentres
        crea_gr = self.create_group_on_subshape

        # Generate the 2D sketch based on the points from the CSV file...
        tref = time.time()
        _mark = gb.MakeMarker(0, 0, 0, 1, 0, 0, 0, 1, 0)
        _sk2d = gb.Sketcher2D()
        _sk2d.addPoint(*coords[0].tolist())
        for coord in coords[1:]:
            _sk2d.addSegmentAbsolute(*coord.tolist())
        _sk2d.close()

        _shape_contour = _sk2d.wire(_mark)

        # Generate a face using this wire and then partition the simulation
        # rectangular face (self.rect)
        _solid_face = gb.MakeFaceWires([_shape_contour], 1)

        partition = gb.MakePartition([self.rect], [_solid_face], [], [],
                                     st['FACE'], 0, [], 0)

        # List all subobjects that are needed to generate the groups later-on
        _all_edges = ss_sorted(partition, st['EDGE'])
        _all_faces = ss_sorted(partition, st['FACE'])

        gb.addToStudy(partition, sid)

        # Generate the solid face group
        gr_solid, _solid_gobjs = crea_gr(partition, _solid_face,
                                         'Solid', 'FACE', _all_faces)

        # Generate the fluid group, by retrieving all faces that are
        # not included in the solid group (just previously created)
        gr_fluid = gb.CreateGroup(partition, st['FACE'])

        _fluid_gobjs = [gob for gob in _all_faces if gob not in _solid_gobjs]
        for gob in _fluid_gobjs:
            eid = gb.GetSubShapeID(partition, gob)
            gb.AddObject(gr_fluid, eid)
        gb.addToStudyInFather(partition, gr_fluid, 'Fluid')

        # Retrieve the Shape contour group
        gr_shape, _cont_gobjs = crea_gr(partition, _shape_contour,
                                        'Shape', 'EDGE', _all_edges)

        # Generate the boundary group, by retrieving all edges that are
        # not included in the shape contour group (just previously created)
        gr_boundary = gb.CreateGroup(partition, st['EDGE'])

        _bdry_gobjs = [gob for gob in _all_edges if gob not in _cont_gobjs]
        for gob in _bdry_gobjs:
            eid = gb.GetSubShapeID(partition, gob)
            gb.AddObject(gr_boundary, eid)
        gb.addToStudyInFather(partition, gr_boundary, 'Boundary')

        delta_sec = time.time() - tref
        ut.print_ok(f'Geometry ({round(delta_sec, 2)}s)')

        # -=-=-=-=-=- M E S H I N G -=-=-=-=-=-
        #
        # Generate mesh based on the geometry using SMESH (SalomeMeca)
        #
        sb = self.smeshb
        sb.SetEnablePublish(ut.DEBUG)

        tref = time.time()
        mesh = sb.Mesh(partition)

        reg_1d = mesh.Segment(geom=gr_shape)
        reg_1d.NumberOfSegments(1)

        reg_1d = mesh.Segment(geom=gr_boundary)
        reg_1d.NumberOfSegments(10)

        netgen_2d = mesh.Triangle(algo=sb.BUILDER.NETGEN_2D)
        _len_from_edges = netgen_2d.LengthFromEdges()

        _gr = mesh.GroupOnGeom(gr_solid, 'Solid', sb.SMESH.FACE)
        sb.SetName(_gr, 'Solid')
        _gr = mesh.GroupOnGeom(gr_fluid, 'Fluid', sb.SMESH.FACE)
        sb.SetName(_gr, 'Fluid')
        _gr = mesh.GroupOnGeom(gr_shape, 'Shape', sb.SMESH.EDGE)
        sb.SetName(_gr, 'Shape')
        _gr = mesh.GroupOnGeom(gr_boundary, 'Boundary', sb.SMESH.EDGE)
        sb.SetName(_gr, 'Boundary')
        _gr = mesh.GroupOnGeom(gr_boundary, 'Boundary', sb.SMESH.NODE)
        sb.SetName(_gr, 'Boundary')

        mesh.Compute()

        ver = 32 # MED Version
        mesh_fn = osp.join(out_dir, 'mesh.med')
        mesh.ExportMED(mesh_fn, 0, ver, 1, None, 0)

        delta_sec = time.time() - tref
        ut.print_ok(f'Mesh ({round(delta_sec, 2)}s)')
        ut.print_('debug', mesh_fn)

        # Cleanup geometric object if not in DEBUG mode...
        if not ut.DEBUG:
            _sobj_ref = self.salome_study.FindObjectIOR(
                self.salome_study.ConvertObjectToIOR(partition))
            if _sobj_ref:
                self.study_builder.RemoveObjectWithChildren(_sobj_ref)


        # -=-=-=-=-=- C O D E _ A S T E R   . C O M M   /  E X P O R T -=-=-=-=-=-
        #
        # Generate the calculation commands file
        #
        comm_fn = osp.join(out_dir, 'case.comm')
        res_output_fn = osp.join(self.output_dir, f'{sid}.csv') # <- added mass
        with open(comm_fn, 'w') as ca_f:
            ca_f.write(self.ca_template.replace('<OUTPUT/PATH>', res_output_fn))
        ut.print_ok('Code_Aster commands file')
        ut.print_('debug', comm_fn)

        if self.ca_export is not None:
            export_fn = osp.join(out_dir, 'export')
            with open(export_fn, 'w') as exp_f:
                exp_f.write(self.ca_export.replace('<SHAPE/ID>', sid))

            ut.print_ok('Code_Aster export file')
            ut.print_('debug', export_fn)

        # Rename original .csv as .csv_ so as a way to indicate that
        # it has been treated and thus skipped in subsequent runs.
        os.rename(path, f'{path}_')

        # -=-=-=-=-=- C O D E   A S T E R    R U N N E R  -=-=-=-=-=-
        #
        # Run added mass calculations using Code_Aster, interactively
        #
        if self._run:
            #
            # Create a code_aster calculation using the AsterStudy API
            # and run the calculations interactively
            #
            ut.print_('calc', f'[{sid}] is being calculated', 'bold')

            tref = time.time()
            calc = self.as_calc_api(out_dir)
            calc.set_output_dir(out_dir)
            calc.set('server', 'localhost')
            calc.set('mode', 'Interactive')
            calc.set('version', 'stable')
            calc.set('no_database', True) # Do not save the base

            # This is not safe, as encoding errors can be obtained
            calc.add_stage_from_file(comm_fn, f'AddedMass_{sid}')

            calc.add_file(mesh_fn, 20, self.as_file_attr.In)
            calc.add_file(osp.join(out_dir, 'message.txt'), 6, self.as_file_attr.Out)
            calc.use_interactive()
            ut.print_ok('Prepared')

            with ut.suppress_stdout_stderr():
                # Actually run the calculation
                calc.run()

            delta_sec = time.time() - tref
            failed = calc.state_name != 'Success'
            if failed:
                ut.print_nook(f'Calculation failed ({round(delta_sec, 2)}s)')
            else:
                ut.print_ok(f'Calculated successfully ({round(delta_sec, 2)}s)')
                if osp.isfile(res_output_fn):
                    majou = np.round(np.genfromtxt(res_output_fn, dtype=float), 4)
                    mx, my, mxy = majou[0, 0], majou[1, 1], majou[0, 1]
                    ut.print_('resu', f'[{sid}] MX = {mx} | MY = {my} | MXY = {mxy}',
                              ('okgreen', 'bold'))

                    # Remove the whole calculation folder if calculation is
                    # successful, and if we are not in debug mode
                    if ut.DEBUG is False:
                        shutil.rmtree(out_dir)


if __name__ == '__main__':
    """
    Main entry point when the script is executed in a python interpreter
    """
    root = osp.join(osp.dirname(__file__), 'output')

    if DATASET_ID:
        points_dir = osp.join(root, DATASET_ID, 'points')
    else:
        # Automatically select the latest dataset directory if DATASET_ID
        # is not set (default).
        all_subdirs = [osp.join(root, d) for d in os.listdir(root) \
                       if os.path.isdir(osp.join(root, d))]
        latest_subdir = max(all_subdirs, key=os.path.getmtime)
        points_dir = osp.join(latest_subdir, 'points')

    runner = SalomeMecaRunner(points_dir, run=True)

    runner.run_all()
